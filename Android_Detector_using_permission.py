import zipfile
import os
import pickle
import joblib
import string
from os import listdir
from nltk.corpus import stopwords
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import CountVectorizer

def process_text(text):
    nopunc = [char for char in str(text) if char not in string.punctuation]
    nopunc = ''.join(nopunc)
    cleaned_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]
    return cleaned_words

path = r'E:\KU-Android\train\KU-Android-pre-train\vir\0-normal\00abc0acaa0b6d24ee4cf00b7ed1cbda2d9fbaf89b056c621204ede40dd23f3d.vir'

zip_name = path.split('\\')[-1]
all_zip = zipfile.ZipFile(path)
zip_parser = zip_name.split('.vir')
unzip = zip_parser[0]
all_zip.extractall(unzip)

path = unzip

file_name = os.path.join(unzip, 'AndroidManifest.xml')
file = open(file_name, 'r', encoding='utf_16_le')

permision_list = list()
line = file.readlines()

txt = ''
for i in range(len(line)):
    txt += line[i]

txt = txt.split('.permission.')
permission = list()
for i in range(2,len(txt)):
    permission.append(txt[i].split('\x00')[0])

print(permission)
row = ""
for p_i in range(len(permission)):
    row += permission[p_i] + " "

test_x = row.split(",")

vectorizer = CountVectorizer()
X = vectorizer.fit_transform(permission)

filename = 'model.sav'
loaded_model = pickle.load(open(filename, 'rb'))
pred_y = loaded_model.predict(test_x)
print(pred_y)

################
#pipeline.steps[1][1].feature_importances_
importances = loaded_model.step[1][1].feature_importances_
#importances = model.feature_importances_
indices = np.argsort(importances)

plt.figure(1)
plt.title('Feature Importances')
plt.barh(range(len(indices)), importances[indices], color='b', align='center')
plt.yticks(range(len(indices)), features[indices])
plt.xlabel('Relative Importance')