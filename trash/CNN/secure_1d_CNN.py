import keras
import os
import PIL
import glob
import cv2
from keras.models import load_model
import keras.backend as K
from os import listdir
import numpy as np
import PIL.Image as pilimg
import numpy as np
from keras.models import Sequential
from keras.layers import Conv1D, BatchNormalization, Dense, Flatten
import matplotlib.pylab as plt
import pandas as pd
from keras import backend as K
from keras import optimizers

Train_path = r'E:\KU-Android\train\KU-Android-pre-train\Test_Room_1\Train'
Train_folder = os.listdir(Train_path)
Train_list = os.listdir(os.path.join(Train_path, Train_folder))

Val_path = r'E:\KU-Android\train\KU-Android-pre-train\Test_Room_1\Val'
Val_folder = os.listdir(Val_path)
Val_list = os.listdir(os.path.join(Val_path, Val_folder))

x_train = list()
y_train = list()
for i in range(len(Train_folder)):
    for j in range(len(Train_list)):
        image = cv2.imread(os.path.join(Train_path, Train_folder[i], Train_list[j]), cv2.IMREAD_GRAYSCALE)
        image.reshape(224, 224).astype('float32') / 255.0
        x_train.append(image)
        y_train.append(i)

x_val = list()
y_val = list()
for i in range(len(Val_folder)):
    for j in range(len(Val_list)):
        image = cv2.imread(os.path.join(Val_path, Val_folder[i], Val_list[j]), cv2.IMREAD_GRAYSCALE)
        image.reshape(224, 224).astype('float32') / 255.0
        x_val.append(image)
        y_val.append(i)

nb_filters = 16
nb_kernels = 10
nb_strides = 2

model = Sequential()
model.add(Conv1D(filters=nb_filters, kernel_size=nb_kernels, strides=nb_strides, activation='relu',
                 input_shape=(224,224)))
model.add(BatchNormalization())
model.add(Conv1D(filters=nb_filters*2, kernel_size=nb_kernels, strides=nb_strides, activation='relu'))
model.add(BatchNormalization())
model.add(Conv1D(filters=nb_filters*4, kernel_size=nb_kernels, strides=nb_strides, activation='relu'))
model.add(BatchNormalization())
model.add(Flatten())
model.add(Dense(units=500, activation='relu'))
model.add(Dense(units=500, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
#model = keras.applications.VGG16(include_top=True, weights=None, input_tensor=None, input_shape=(224, 224, 3), pooling='max', classes=1)
model.summary()
#load_weight

SGD = optimizers.SGD(lr=0.001, decay = 0.005, momentum=0.9)
model.compile(loss='binary_crossentropy', optimizer='SGD', metrics=['accuracy'])

# this is the augmentation configuration we will use for training

from keras.callbacks import ModelCheckpoint
from keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(monitor='val_loss', patience=400, verbose=1, mode='auto')
tb_hist = keras.callbacks.TensorBoard(log_dir = r'C:\Users\User\.PyCharmCE2017.3\config\scratches\graph', histogram_freq = 0, write_graph = True, write_images = True)
checkpointer = ModelCheckpoint(filepath=r'C:\Users\User\.PyCharmCE2017.3\config\scratches\tmp\secure_1104.h5', monitor ='val_loss', verbose=1, save_best_only=True)
callback_list = [early_stopping, tb_hist, checkpointer]

batch_size = 16
model.fit(x=x_train, y=y_train, epochs=5000, batch_size=batch_size, validation_data=(x_val, y_val), verbose=2, callbacks = callback_list)
